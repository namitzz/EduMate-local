# EduMate Environment Configuration Example
# Copy this file to .env and adjust as needed

# ============================================
# Backend Configuration
# ============================================

# Fast Mode (set to 1 to enable optimizations for 6-student pilot)
# When enabled: smaller chunks, fewer retrievals, faster responses
# Default: 1 (enabled) for optimal performance
FAST_MODE=1

# Ollama Configuration
# ─────────────────────────────────────────────────────────────────
# IMPORTANT: Set OLLAMA_URL based on your deployment type:
#
# 1. LOCAL DEVELOPMENT (non-Docker):
#    OLLAMA_URL=http://localhost:11434
#    → Use this when running Ollama on your local machine
#    → Default if not set
#
# 2. DOCKER DEPLOYMENT:
#    OLLAMA_HOST=http://ollama:11434
#    → Set in docker-compose.yml (auto-configured)
#    → Uses container-to-container networking
#
# 3. CLOUD/PUBLIC API DEPLOYMENT (Fly.io, Streamlit Cloud, Railway, etc.):
#    OLLAMA_URL=https://your-ollama-api-endpoint.com
#    → Use your assigned public/shared Ollama API endpoint
#    → Examples: https://api.ollama.ai, https://your-instance.fly.dev
#    → Do NOT use localhost - it won't work in cloud deployments
#    → Check if your provider requires API key authentication
#
# For local development, use the default:
OLLAMA_URL=http://localhost:11434

# Model to use (smaller models = faster responses)
OLLAMA_MODEL=mistral:latest

# For faster responses in pilot, consider a smaller model:
# OLLAMA_MODEL=qwen2.5:1.5b-instruct

# Generation Settings
MAX_ACTIVE_GENERATIONS=1  # Concurrency limit (1 = sequential)
TEMP=0.3                  # Temperature for generation (0.0-1.0)
NUM_PREDICT=400           # Max tokens to generate (default 400 for faster responses)

# ============================================
# UI Configuration
# ============================================

# Backend API URL for the UI to connect to
EDUMATE_API_URL=http://localhost:8000
# For Docker: EDUMATE_API_URL=http://backend:8000

# Alternative name for API base (backward compatibility)
API_BASE=http://localhost:8000

# ============================================
# Docker Compose
# ============================================

COMPOSE_PROJECT_NAME=edumate-local
