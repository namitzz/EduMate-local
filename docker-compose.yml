services:
  ollama:
    image: ollama/ollama:latest
    container_name: edumate-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"          # optional: access from host too
    volumes:
      - ollama:/root/.ollama   # persist models inside a Docker volume
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 10

  # Initialization service: pulls model and runs ingestion
  init:
    build:
      context: ./backend
    container_name: edumate-init
    environment:
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: mistral
    volumes:
      - ./backend:/app
      - ./corpus:/app/corpus
      - ./backend/chroma_db:/app/chroma_db
      - ./scripts:/scripts
    depends_on:
      ollama:
        condition: service_healthy
    command: ["/bin/bash", "/scripts/docker-init.sh"]

  api:
    build:
      context: ./backend
    container_name: edumate-local-api-1
    restart: unless-stopped
    environment:
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: mistral # talk to the service by name
    volumes:
      - ./backend:/app
      - ./corpus:/app/corpus
      - ./backend/chroma_db:/app/chroma_db
    ports:
      - "8000:8000"
    depends_on:
      init:
        condition: service_completed_successfully

  ui:
    build:
      context: ./ui
    container_name: edumate-local-ui-1
    restart: unless-stopped
    environment:
      API_BASE: http://api:8000
    volumes:
      - ./ui:/app
    ports:
      - "8501:8501"
    depends_on:
      - api

volumes:
  ollama:

